# Audio Deepfake Detection System

An end-to-end deep learning solution to classify audio as **REAL** or **FAKE** using 2D Convolutional Neural Networks (CNN) and Mel-Spectrogram analysis.

## ğŸš€ Project Overview
This project addresses the growing threat of synthetic audio (Deepfakes) generated by Text-to-Speech (TTS) and Voice Conversion (VC) technologies. By converting raw audio into Mel-Spectrograms, we treat the detection problem as an image classification task, leveraging the power of CNNs to identify spectral artifacts left by generative models.

## ğŸ§  Model Architecture
- **Input**: Mel-Spectrogram (128 Mel bands)
- **Architecture**: 4-layer 2D CNN with Batch Normalization and Max Pooling.
- **Output**: Binary classification (Bona fide vs. Spoof).
- **Loss Function**: Binary Cross-Entropy.
- **Optimizer**: Adam.

## ğŸ“ Project Structure
```text
audio-deepfake-detection/
â”‚
â”œâ”€â”€ data/               # Dataset storage (ASVspoof 2019)
â”œâ”€â”€ notebooks/          # Google Colab compatible training notebooks
â”‚   â””â”€â”€ training.ipynb
â”œâ”€â”€ model/              # Saved model weights (.pth)
â”œâ”€â”€ src/                # Source code for model and training
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ app.py              # Streamlit Web UI
â”œâ”€â”€ utils.py            # Preprocessing and visualization utilities
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Project documentation
```

## ğŸ› ï¸ Installation & Usage

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/audio-deepfake-detection.git
cd audio-deepfake-detection
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the App
```bash
streamlit run app.py
```

## ğŸ§ª Training on Google Colab
The `notebooks/training.ipynb` is designed to run seamlessly on Google Colab. It includes:
- Automatic mounting of Google Drive.
- Dataset downloading and extraction logic.
- GPU-accelerated training.
- Evaluation metrics (Accuracy, EER, Confusion Matrix).

## ğŸ“Š Evaluation Metrics
We use the **Equal Error Rate (EER)** as the primary metric, consistent with the ASVspoof challenge standards. Additionally, we provide:
- **ROC Curve**
- **Confusion Matrix**
- **Precision, Recall, and F1-Score**

## â˜ï¸ Deployment
This app is ready for deployment on **Streamlit Cloud** or **Hugging Face Spaces**.
1. Push the code to a GitHub repository.
2. Connect the repository to Streamlit Cloud.
3. Ensure `requirements.txt` is in the root directory.

## ğŸ“ Academic Context
This project is suitable for:
- **Final Year Projects**: Demonstrates end-to-end ML pipeline.
- **Research**: Baseline for synthetic speech detection.
- **Portfolio**: Showcases full-stack AI development skills.

---
*Developed by Manus AI*
